{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.nn.modules.normalization as norm\n",
    "from torch.autograd import Variable\n",
    "from process_data import ALOVDataset\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRN(nn.Module):\n",
    "    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=True):\n",
    "        super(LRN, self).__init__()\n",
    "        self.ACROSS_CHANNELS = ACROSS_CHANNELS\n",
    "        if ACROSS_CHANNELS:\n",
    "            self.average=nn.AvgPool3d(kernel_size=(local_size, 1, 1),\n",
    "                    stride=1,\n",
    "                    padding=(int((local_size-1.0)/2), 0, 0))\n",
    "        else:\n",
    "            self.average=nn.AvgPool2d(kernel_size=local_size,\n",
    "                    stride=1,\n",
    "                    padding=int((local_size-1.0)/2))\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.ACROSS_CHANNELS:\n",
    "            div = x.pow(2).unsqueeze(1)\n",
    "            div = self.average(div).squeeze(1)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        else:\n",
    "            div = x.pow(2)\n",
    "            div = self.average(div)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        x = x.div(div)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alexnet = models.alexnet(pretrained=True)\n",
    "class alexnet_conv_layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(alexnet_conv_layers, self).__init__()\n",
    "        input_channels = 3\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, out_channels=96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            norm.LocalResponseNorm(size=2, alpha=2e-5, beta=0.75, k=1.0)\n",
    "        )\n",
    "        self.skip1 = nn.Sequential(\n",
    "            nn.Conv2d(96, out_channels=16, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, groups=2, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            norm.LocalResponseNorm(size=2, alpha=2e-5, beta=0.75, k=1.0)\n",
    "        )\n",
    "\n",
    "        self.skip2 = nn.Sequential(\n",
    "            nn.Conv2d(256, out_channels=32, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1, groups=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1, groups=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool5 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv5_flat = nn.Sequential(\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.skip5 = nn.Sequential(\n",
    "            nn.Conv2d(256, out_channels=64, kernel_size=1, stride=1),\n",
    "            nn.PReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Linear(37104 * 2, 2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_out1 = self.conv1(x)\n",
    "        x_out_skip1 = self.skip1(x_out1)\n",
    "\n",
    "        x_out2 = self.conv2(x_out1)\n",
    "        x_out_skip2 = self.skip2(x_out2)\n",
    "\n",
    "        x_out3 = self.conv3(x_out2)\n",
    "        x_out4 = self.conv4(x_out3)\n",
    "        x_out5 = self.conv5(x_out4)\n",
    "\n",
    "        x_out_skip5 = self.skip5(x_out5)\n",
    "\n",
    "        x_out_pool =self.pool5(x_out5)\n",
    "        x_out_pool = self.conv5_flat( x_out_pool)\n",
    "        x_out = torch.cat((x_out_skip1, x_out_skip2, x_out_skip5, x_out_pool), dim=1)\n",
    "\n",
    "        y_out1 = self.conv1(x)\n",
    "        y_out_skip1 = self.skip1(y_out1)\n",
    "\n",
    "        y_out2 = self.conv2(y_out1)\n",
    "        y_out_skip2 = self.skip2(y_out2)\n",
    "\n",
    "        y_out3 = self.conv3(y_out2)\n",
    "        y_out4 = self.conv4(y_out3)\n",
    "        y_out5 = self.conv5(y_out4)\n",
    "\n",
    "        y_out_skip5 = self.skip5(y_out5)\n",
    "\n",
    "        y_out_pool =self.pool5(y_out5)\n",
    "        y_out_pool = self.conv5_flat(y_out_pool)\n",
    "        y_out = torch.cat((y_out_skip1, y_out_skip2, y_out_skip5, y_out_pool), dim=1)\n",
    "\n",
    "        final_out = torch.cat((x_out, y_out), dim=1)\n",
    "        conv_out = self.conv6(final_out)\n",
    "        return conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Re3Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Re3Net,self).__init__()\n",
    "        self.conv_layers = alexnet_conv_layers()\n",
    "        \n",
    "        #2048 from conv_layers? maybe 1024?\n",
    "        self.lstm1 =nn.LSTMCell(2048, LSTM_SIZE)\n",
    "        self.lstm2 = nn.LSTMCell(2048 + LSTM_SIZE, LSTM_SIZE)\n",
    "\n",
    "        self.fc_final = nn.Linear(LSTM_SIZE,4)\n",
    "\n",
    "        self.h0=Variable(torch.rand(1,1024)).cuda()\n",
    "        self.c0=Variable(torch.rand(1,1024)).cuda()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        self.h0 = Variable(torch.rand(1, 1024))\n",
    "        self.c0 = Variable(torch.rand(1, 1024))\n",
    "\n",
    "    def forward(self, x, prev_LSTM_state=False):\n",
    "        out = self.conv_layers(x)\n",
    "\n",
    "        lstm_out, self.h0 = self.lstm1(out, (self.h0, self.c0))\n",
    "\n",
    "        lstm2_in = torch.cat((out, lstm_out), dim=1)\n",
    "\n",
    "        lstm2_out, h1 = self.lstm2(lstm2_in, (self.h0, self.c0))\n",
    "\n",
    "        out = self.fc_final(lstm2_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningAverage():\n",
    "    \"\"\"A simple class that maintains the running average of a quantity\n",
    "    Example:\n",
    "    ```\n",
    "    loss_avg = RunningAverage()\n",
    "    loss_avg.update(2)\n",
    "    loss_avg.update(4)\n",
    "    loss_avg() = 3\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.total = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.total += val\n",
    "        self.steps += 1\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.total / float(self.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, dataloader, metrics, params):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = RunningAverage()\n",
    "    counter=0\n",
    "    for i,data in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        x1, x2, y = data['previmg'], data['currimg'], data['currbb']\n",
    "        output = model(x1, x2)\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward(retain_graph=True)\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()\n",
    "        if i % params.save_summary_steps == 0:\n",
    "            # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "            output = output.data.cpu().numpy()\n",
    "            # compute all metrics on this batch\n",
    "            summary_batch = {}\n",
    "            summary_batch['loss'] = loss.data[0]\n",
    "            summ.append(summary_batch)\n",
    "            logging.info('- Average Loss for iteration {} is {}'.format(i,loss.data[0]/params.batch_size))\n",
    "\n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.data[0])\n",
    "        counter+=1\n",
    "\n",
    "    print(counter)\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric: np.mean([x[metric] for x in summ]) for metric in summ[0]}\n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    logging.info(\"- Train metrics: \" + metrics_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloader, optim, loss_function, num_epochs):\n",
    "\n",
    "    dataset_size = dataloader.dataset.len\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        curr_loss = 0.0\n",
    "\n",
    "        # currently training on just ALOV dataset\n",
    "        i = 0\n",
    "        for data in dataloader:\n",
    "\n",
    "            x1, x2, y = data['previmg'], data['currimg'], data['currbb']\n",
    "            if use_gpu:\n",
    "                x1, x2, y = Variable(x1.cuda()), Variable(x2.cuda()), Variable(y.cuda(), requires_grad=False)\n",
    "            else:\n",
    "                x1, x2, y = Variable(x1), Variable(x2), Variable(y, requires_grad=False)\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            output = net(x1,x2)\n",
    "            loss = loss_function(output, y)\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            optim.step()\n",
    "            if i%20 == 0:\n",
    "                print('[training] epoch = %d, i = %d/%d, loss = %f' % (epoch, i, dataset_size\t\t\t,loss.data[0]) )\n",
    "                sys.stdout.flush()\n",
    "            i = i + 1\n",
    "            curr_loss += loss.data[0]\n",
    "\n",
    "        epoch_loss = curr_loss / dataset_size\n",
    "        print('Loss: {:.4f}'.format(epoch_loss))\n",
    "        \n",
    "        path = save_directory + '_batch_' + str(epoch) + '_loss_' + str(round(epoch_loss, 3)) + '.pth'\n",
    "        torch.save(net.state_dict(), path)\n",
    "\n",
    "        val_loss = evaluate(net, dataloader, loss_function, epoch)\n",
    "        print('Validation Loss: {:.4f}'.format(val_loss))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to torch tensors\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        prev_img, curr_img = sample['previmg'], sample['currimg']\n",
    "        # swap color axis because numpy image: H x W x C ; torch image: C X H X W\n",
    "        prev_img = prev_img.transpose((2, 0, 1))\n",
    "        curr_img = curr_img.transpose((2, 0, 1))\n",
    "        if 'currbb' in sample:\n",
    "            currbb = sample['currbb']\n",
    "            return {'previmg': torch.from_numpy(prev_img).float(),\n",
    "                    'currimg': torch.from_numpy(curr_img).float(),\n",
    "                    'currbb': torch.from_numpy(currbb).float()\n",
    "                    }\n",
    "        else:\n",
    "            return {'previmg': torch.from_numpy(prev_img).float(),\n",
    "                    'currimg': torch.from_numpy(curr_img).float()\n",
    "                    }\n",
    "\n",
    "\n",
    "# To normalize the data points\n",
    "class Normalize(object):\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        prev_img, curr_img = sample['previmg'], sample['currimg']\n",
    "        self.mean = [104, 117, 123]\n",
    "        prev_img = prev_img.astype(float)\n",
    "        curr_img = curr_img.astype(float)\n",
    "        prev_img -= np.array(self.mean).astype(float)\n",
    "        curr_img -= np.array(self.mean).astype(float)\n",
    "\n",
    "        if 'currbb' in sample:\n",
    "            currbb = sample['currbb']\n",
    "            currbb = currbb*(10./227);\n",
    "            return {'previmg': prev_img,\n",
    "                    'currimg': curr_img,\n",
    "                    'currbb': currbb}\n",
    "        else:\n",
    "            return {'previmg': prev_img,\n",
    "                    'currimg': curr_img\n",
    "}\n",
    "transform = transforms.Compose([Normalize(), ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = 'saved_models/'\n",
    "save_model_step = 5\n",
    "learning_rate = 0.00001\n",
    "use_gpu = True\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alov = ALOVDataset('../data/alov/imagedata++/', '../data/alov/alov300++_rectangleAnnotation_full/', transform)\n",
    "dataloader = DataLoader(alov, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Re3Net().cuda()\n",
    "loss_function = torch.nn.L1Loss(size_average=False).cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00001, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Directory %s already exists', 'saved_models/')\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(save_directory):\n",
    "    print('Directory %s already exists', save_directory)\n",
    "else:\n",
    "    os.makedirs(save_directory)\n",
    "    print('Create directory: %s', save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "parallel_for failed: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-bee7f46fc72f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-bc6871be6990>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, dataloader, optim, loss_function, num_epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: parallel_for failed: out of memory"
     ]
    }
   ],
   "source": [
    "net = train_model(net, dataloader, optimizer, loss_function, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
